{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf1450c",
   "metadata": {},
   "source": [
    "# Customer Satisfaction Analysis\n",
    "\n",
    "A startup in the logistics and delivery space surveyed their customers regarding the service provided. The aim of this analysis is to determine key features that they should work on to further improve customer satisfaction. \n",
    "\n",
    "## Goal\n",
    "The goal is to try and predict if a customer is happy or not based on the answers they give to the questions being asked. Identify imortant features, and suggest imporvements for future questionaires. \n",
    "\n",
    "\n",
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3435d724",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3680\\3801973697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, roc_auc_score, roc_curve, auc, f1_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3980275c",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee87cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88195594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ec9a4",
   "metadata": {},
   "source": [
    "### Target\n",
    "Y = Labelled target class where 0 indicates unhappy customers and 1 indicates happy customers. \n",
    "\n",
    "### Features\n",
    "\n",
    "X1 = My order was delivered on time <br>\n",
    "X2 = Contents of my order was as I expected <br>\n",
    "X3 = I ordered everything I wanted to order <br>\n",
    "X4 = I paid a good price for my order <br>\n",
    "X5 = I am satisfied with my courier <br>\n",
    "X6 = The app makes ordering easy for me <br>\n",
    "\n",
    "Each of these have a label from 1-5 from customers where a higher number indicates higher satisfaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b721802",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d83eb",
   "metadata": {},
   "source": [
    "### Problem: \n",
    "So we have Y has the target column, and then we have 6 attritbutes. However we seem to only have 126 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0dd52e",
   "metadata": {},
   "source": [
    "No missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afa981",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd975e12",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fbf17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ff86f",
   "metadata": {},
   "source": [
    "X1 = 'My order was delivered on time' only has values 1, 3, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data.groupby('Y').count().plot(kind='bar')\n",
    "ax.set_xticklabels(['Unhappy[0]', 'Happy[1]'], rotation = 0)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141598f",
   "metadata": {},
   "source": [
    "We have an unbalanced dataset: there are more datapoints referring to class 0 than to class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , axes = plt.subplots(2,3, sharey= True, figsize = (15,10))\n",
    "fig.suptitle('Distribution of Customer Satisfaction Ratings for Different Features')\n",
    "\n",
    "sns.countplot(ax = axes[0,0], x=data['X1'], hue=data['Y'], palette='mako')\n",
    "axes[0,0].set_title('X1: My order was delivered on time')\n",
    "\n",
    "sns.countplot(ax = axes[0,1], x=data['X2'], hue=data['Y'], palette='mako')\n",
    "axes[0,1].set_title('X2: Contents of my order was as I expected')\n",
    "\n",
    "sns.countplot(ax = axes[0,2], x=data['X3'], hue=data['Y'], palette='mako')\n",
    "axes[0,2].set_title('X3: I ordered everything I wanted to order')\n",
    "\n",
    "sns.countplot(ax = axes[1,0], x=data['X4'], hue=data['Y'], palette='mako')\n",
    "axes[1,0].set_title('X4: I paid a good price for my order')\n",
    "\n",
    "sns.countplot(ax = axes[1,1], x=data['X5'], hue=data['Y'], palette='mako')\n",
    "axes[1,1].set_title('X5: I am satisfied with my courier')\n",
    "\n",
    "sns.countplot(ax = axes[1,2], x=data['X6'], hue=data['Y'], palette='mako')\n",
    "axes[1,2].set_title('X6: The app makes ordering easy for me')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04635aab",
   "metadata": {},
   "source": [
    "### Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958e02e",
   "metadata": {},
   "source": [
    "The features don't seem symmetrical. Let's work out the skew to confirm the nature of the distributions. I'll use pandas .skew() function. <br>\n",
    "\n",
    "For reference: https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics <br>\n",
    "If the skewness is between -0.5 and 0.5, the data are fairly symmetrical <br>\n",
    "If the skewness is between -1 and â€“ 0.5 or between 0.5 and 1, the data are moderately skewed <br>\n",
    "If the skewness is less than -1 or greater than 1, the data are highly skewed <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16418be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Y', axis = 1).agg(['skew']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a7de2",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a260ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize=(10,5))\n",
    "sns.heatmap(data.corr(), annot = True).set(title='Correlation Between Features')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e273157",
   "metadata": {},
   "source": [
    "If we found two features to have a high correlation it would have been worth considering dropping one of those features. However, none of the features are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f631b7",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Y', axis = 1)\n",
    "y = data['Y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d00105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of dataset in Class 0: ', data[data['Y'] == 0].shape[0]/len(data)*100)\n",
    "print('Percentage of dataset in Class 1: ', data[data['Y'] == 1].shape[0]/len(data)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e834f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of Class 0 in training set:', np.count_nonzero(y_train == 0)/len(y_train)*100)\n",
    "print('Percentage of Class 1 in training set:', np.count_nonzero(y_train == 1)/len(y_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of Class 0 in validation set:', np.count_nonzero(y_test == 0)/len(y_test)*100)\n",
    "print('Percentage of Class 1 in validation set:', np.count_nonzero(y_test == 1)/len(y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036132bc",
   "metadata": {},
   "source": [
    "## Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af33e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier()\n",
    "dummy_model.fit(X_train, y_train)\n",
    "dummy_model.score(y_test, dummy_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc694c30",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ae1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = LogisticRegression(random_state = 10)\n",
    "base_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = base_lr.predict(X_test)\n",
    "training_score = base_lr.fit(X_train, y_train).score(X_train, y_train)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "print('Training Set score: ', training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2cd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-3,3,7),\n",
    "       'penalty': ['l1','l2'],\n",
    "       'solver': ['lbfgs', 'liblinear']}\n",
    "grid_lg = GridSearchCV(LogisticRegression(random_state = 10), param_grid, cv=10, scoring='accuracy')\n",
    "grid_lg.fit(X_train, y_train)\n",
    "print('Mean Cross Validation Score:' ,grid_lg.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ',grid_lg.best_params_)\n",
    "print(\"Logistic Model's Best Accuracy: \", grid_lg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "y_pred_prob = grid_lg.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.savefig('roc_best_random.png', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print('Area Under Curve: ',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cebee8c",
   "metadata": {},
   "source": [
    "## KNearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68018d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_knn = KNeighborsClassifier()\n",
    "base_knn.fit(X_train, y_train)\n",
    "y_pred = base_knn.predict(X_test)\n",
    "training_score = base_knn.fit(X_train, y_train).score(X_train, y_train)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "print('Training Set Score: ', training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'leaf_size':list(range(1,15)), \n",
    "              'n_neighbors':list(range(1,15)), \n",
    "              'p':[1,2]} #p=1 is Manhatten Distance and p=2 is Euclidean Distances \n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, scoring='accuracy')\n",
    "grid_knn.fit(X_train, y_train)\n",
    "print('Mean Cross Validation Score:' ,grid_knn.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ',grid_knn.best_params_)\n",
    "print(\"K Nearest Nieghbors Model's Best Accuracy: \", grid_knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6674fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "y_pred_prob = grid_knn.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.savefig('roc_best_random.png', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print('Area Under Curve: ',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b2db0",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ac4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rfc = RandomForestClassifier()\n",
    "base_rfc.fit(X_train, y_train)\n",
    "y_pred = base_rfc.predict(X_test)\n",
    "training_score = base_rfc.fit(X_train, y_train).score(X_train, y_train)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "print('Training Set Score: ', training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c30dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':np.arange(1,50), \n",
    "              'max_depth': np.arange(1,10),\n",
    "             'criterion': ['gini', 'entropy']}\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(random_state = 10), param_grid, cv=2, scoring = 'accuracy')\n",
    "grid_rfc.fit(X_train, y_train)\n",
    "print('Mean Cross Validation Score:' ,grid_rfc.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ',grid_rfc.best_params_)\n",
    "print(\"Random Forest Classifier Model's Best Accuracy: \", grid_rfc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc9d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "y_pred_prob = grid_rfc.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.savefig('roc_best_random.png', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print('Area Under Curve: ',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5abd6c",
   "metadata": {},
   "source": [
    "### Feature Engineering with Random Forest Classifier\n",
    "\n",
    "As one of our goals is the identify important features, let's have a look at the key features. Our goal is to try and exclude the 'less' imporant features and see if dropping these further imporves the model or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42475156",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state = 10, criterion = 'entropy', max_depth = 5, n_estimators = 26)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "sorted_importances = rfc.feature_importances_.argsort()\n",
    "_ = plt.figure(figsize=(15,10))\n",
    "_ = plt.barh(X.columns[sorted_importances], rfc.feature_importances_[sorted_importances])\n",
    "_ = plt.title('Feature Importance using GridSearch for Hyperparameter Tuning')\n",
    "_ = plt.savefig('feature_imp_grid.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c77d23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d16a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_features = data.drop(['X5', 'X2', 'X4'], axis = 1)\n",
    "top_3_features\n",
    "X_imp = top_3_features.drop('Y', axis = 1)\n",
    "y_imp = top_3_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "rfc = RandomForestClassifier(random_state = 10, criterion = 'entropy', max_depth = 5, n_estimators = 26)\n",
    "model = rfc.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a7f946",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_4_features = data.drop(['X4', 'X2'], axis = 1)\n",
    "X_imp = top_4_features.drop('Y', axis = 1)\n",
    "y_imp = top_4_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "rfc = RandomForestClassifier(random_state = 10, criterion = 'entropy', max_depth = 5, n_estimators = 26)\n",
    "model = rfc.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6f2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_features = data.drop(['X4'], axis = 1)\n",
    "X_imp = top_5_features.drop('Y', axis = 1)\n",
    "y_imp = top_5_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "rfc = RandomForestClassifier(random_state = 10, criterion = 'entropy', max_depth = 5, n_estimators = 26)\n",
    "model = rfc.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394b10d",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_svc = SVC(random_state = 10)\n",
    "base_svc.fit(X_train, y_train)\n",
    "y_pred = base_svc.predict(X_test)\n",
    "training_score = base_svc.fit(X_train, y_train).score(X_train, y_train)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "print('Training Set Score: ', training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c68234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-3,3,7), \n",
    "              'gamma': [1,0.1,0.01,0.001,0.0001], \n",
    "              'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "             'probability': [True]} \n",
    "grid_svc = GridSearchCV(SVC(random_state = 10), param_grid, cv=2, scoring = 'accuracy')\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print('Mean Cross Validation Score:' ,grid_svc.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ',grid_svc.best_params_)\n",
    "print(\"Support Vector Classifier Model's Best Accuracy: \", grid_svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "y_pred_prob = grid_svc.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.savefig('roc_best_random.png', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print('Area Under Curve: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f05a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-3,3,7), \n",
    "              'gamma': [1,0.1,0.01,0.001,0.0001], \n",
    "              'kernel': [\"linear\"], \n",
    "             'probability': [True]} \n",
    "grid_svc = GridSearchCV(SVC(random_state = 10), param_grid, cv=2, scoring = 'accuracy')\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print('Mean Cross Validation Score:' ,grid_svc.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ',grid_svc.best_params_)\n",
    "print(\"Support Vector Classifier Model's Best Accuracy: \", grid_svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6667a69",
   "metadata": {},
   "source": [
    "#### Feature engineering with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear_model = SVC(C = 0.1, gamma = 1, kernel = 'linear', probability = True)\n",
    "model = svc_linear_model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print('Error in training set: ', model.score(X_train, y_train))\n",
    "print('Accuracy Score', accuracy_score(y_test, y_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(y_test, y_pred))\n",
    "fig = pd.Series(abs(model.coef_[0]), index=X.columns).nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b382f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_2_features = data.drop(['X2', 'X3', 'X6', 'X4'], axis = 1)\n",
    "top_2_features\n",
    "X_imp = top_2_features.drop('Y', axis = 1)\n",
    "y_imp = top_2_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "svc = svc_linear_model = SVC(C = 0.1, gamma = 1, kernel = 'linear', probability = True)\n",
    "model = svc.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = data.drop(['X2', 'X3', 'X6', 'X4', 'X5'], axis = 1)\n",
    "top_features\n",
    "X_imp = top_features.drop('Y', axis = 1)\n",
    "y_imp = top_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "svc = svc_linear_model = SVC(C = 0.1, gamma = 1, kernel = 'linear', probability = True)\n",
    "model = svc.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6addd",
   "metadata": {},
   "source": [
    "By dropping the features we do see a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767ffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39ec6b1b",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e395e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gbc = GradientBoostingClassifier()\n",
    "base_gbc.fit(X_train, y_train)\n",
    "y_pred = base_gbc.predict(X_test)\n",
    "training_score = base_gbc.fit(X_train, y_train).score(X_train, y_train)\n",
    "print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n",
    "print('Training Set Score: ', training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0476697",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "grid_gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, scoring = 'accuracy', cv = 2)\n",
    "grid_gbc.fit(X_train, y_train)\n",
    "print('Mean Cross Validation Score:' ,grid_gbc.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ', grid_gbc.best_params_)\n",
    "print(\"Gradient Boosting Classifier Model's Best Accuracy: \", grid_gbc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "y_pred_prob = grid_gbc.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.savefig('roc_best_random.png', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print('Area Under Curve: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier( criterion = 'friedman_mse',\n",
    "                                 learning_rate = 0.075,\n",
    "                                 max_depth = 5,\n",
    "                                 max_features = 'sqrt', \n",
    "                                 min_samples_leaf = 0.1,\n",
    "                                 min_samples_split = 0.28181818181818186, \n",
    "                                 n_estimators = 10, \n",
    "                                 subsample = 0.95)\n",
    "gbc.fit(X_train, y_train)\n",
    "y_pred = gbc.predict(X_test)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "sorted_importances = gbc.feature_importances_.argsort()\n",
    "_ = plt.figure(figsize=(15,10))\n",
    "_ = plt.barh(X.columns[sorted_importances], gbc.feature_importances_[sorted_importances])\n",
    "_ = plt.title('Feature Importance using GridSearch for Hyperparameter Tuning')\n",
    "_ = plt.savefig('feature_imp_grid.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d3dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_features = data.drop(['X2', 'X4', 'X3'], axis = 1)\n",
    "top_3_features\n",
    "X_imp = top_3_features.drop('Y', axis = 1)\n",
    "y_imp = top_3_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "gbc = GradientBoostingClassifier( criterion = 'friedman_mse',\n",
    "                                 learning_rate = 0.075,\n",
    "                                 max_depth = 5,\n",
    "                                 max_features = 'sqrt', \n",
    "                                 min_samples_leaf = 0.1,\n",
    "                                 min_samples_split = 0.28181818181818186, \n",
    "                                 n_estimators = 10, \n",
    "                                 subsample = 0.95)\n",
    "model = gbc.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12194b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_4_features = data.drop(['X2', 'X4'], axis = 1)\n",
    "X_imp = top_4_features.drop('Y', axis = 1)\n",
    "y_imp = top_4_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "gbc = GradientBoostingClassifier( criterion = 'friedman_mse',\n",
    "                                 learning_rate = 0.075,\n",
    "                                 max_depth = 5,\n",
    "                                 max_features = 'sqrt', \n",
    "                                 min_samples_leaf = 0.1,\n",
    "                                 min_samples_split = 0.28181818181818186, \n",
    "                                 n_estimators = 10, \n",
    "                                 subsample = 0.95)\n",
    "model = gbc.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970bbaa5",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc40b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_xgb = XGBClassifier(random_state = 10)\n",
    "base_xgb.fit(X_train, y_train)\n",
    "y_pred = base_xgb.predict(X_test)\n",
    "training_score = base_xgb.fit(X_train, y_train).score(X_train, y_train)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "print('Training Set Score: ', training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd90218",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid =  {'objective':['binary:logistic'],\n",
    "              'booster':['gbtree','gblinear'],\n",
    "              'learning_rate': [0.1], \n",
    "              'max_depth': [7,10,15,20],\n",
    "              'min_child_weight': [10,15,20,25],\n",
    "              'colsample_bytree': [0.8, 0.9, 1],\n",
    "              'n_estimators': [300,400,500,600],\n",
    "              \"reg_alpha\"   : [0.5,0.2,1],\n",
    "              \"reg_lambda\"  : [2,3,5],\n",
    "              \"gamma\"       : [1,2,3]}\n",
    "grid_xgb = GridSearchCV(XGBClassifier(), param_grid, scoring= 'accuracy', cv = 2)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print('Mean Cross Validation Score:' ,grid_xgb.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ', grid_xgb.best_params_)\n",
    "print(\"XGBoost Classifier Model's Best Accuracy: \", grid_xgb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "y_pred_prob = grid_xgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.savefig('roc_best_random.png', bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print('Area Under Curve: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier( booster = 'gbtree', \n",
    "                    colsample_bytree = 0.8, \n",
    "                    gamma = 1, \n",
    "                    learning_rate = 0.1, \n",
    "                    max_depth = 7, \n",
    "                    min_child_weight = 10, \n",
    "                    n_estimators = 300,\n",
    "                    objective = 'binary:logistic', \n",
    "                    reg_alpha = 0.5, \n",
    "                    reg_lambda = 25)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "sorted_importances = xgb.feature_importances_.argsort()\n",
    "_ = plt.figure(figsize=(15,10))\n",
    "_ = plt.barh(X.columns[sorted_importances], xgb.feature_importances_[sorted_importances])\n",
    "_ = plt.title('Feature Importance using GridSearch for Hyperparameter Tuning')\n",
    "_ = plt.savefig('feature_imp_grid.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93673f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = data.drop(['X2', 'X4', 'X3', 'X6', 'X5'], axis = 1)\n",
    "X_imp = top_features.drop('Y', axis = 1)\n",
    "y_imp = top_features['Y']\n",
    "Ximp_train, Ximp_test, yimp_train, yimp_test = train_test_split(X_imp.values, y_imp.values, test_size = 0.2, random_state = 10)\n",
    "xgb = XGBClassifier( booster = 'gbtree', \n",
    "                    colsample_bytree = 0.8, \n",
    "                    gamma = 1, \n",
    "                    learning_rate = 0.1, \n",
    "                    max_depth = 7, \n",
    "                    min_child_weight = 10, \n",
    "                    n_estimators = 300,\n",
    "                    objective = 'binary:logistic', \n",
    "                    reg_alpha = 0.5, \n",
    "                    reg_lambda = 25)\n",
    "model = xgb.fit(Ximp_train, yimp_train)\n",
    "print('Training Set Score:', model.score(Ximp_train, yimp_train))\n",
    "yimp_pred = model.predict(Ximp_test)\n",
    "print('Accuracy Score', accuracy_score(yimp_test, yimp_pred))\n",
    "print('Area Under the ROC: ', roc_auc_score(yimp_test, yimp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936943f",
   "metadata": {},
   "source": [
    "## Stacked Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76241b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingCVClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1214b19",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cfec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = KNeighborsClassifier()\n",
    "classifier2 = XGBClassifier(random_state = 10)\n",
    "classifier3 = SVC(random_state = 10)\n",
    "meta_classifier = LogisticRegression(random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ace4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier = StackingCVClassifier(classifiers = [classifier1, classifier2, classifier3], \n",
    "                                          meta_classifier= meta_classifier, \n",
    "                                          random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff05664",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_pred = stacking_classifier.predict(X_test)\n",
    "print('\\n Accuracy Score of Base Model: ', accuracy_score(y_test, y_pred))\n",
    "print('\\n')\n",
    "stacking_classifier = StackingCVClassifier(classifiers = [classifier1, classifier2, classifier3], \n",
    "                                          meta_classifier= meta_classifier, \n",
    "                                          random_state = 10)\n",
    "print('\\n Training Set Score: ', stacking_classifier.fit(X, y).score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa66a2d",
   "metadata": {},
   "source": [
    "### Hypertuning Parameters for Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1_tuned = KNeighborsClassifier(n_neighbors= 1, p= 1, leaf_size = 2)\n",
    "classifier2_tuned = XGBClassifier(booster = 'gbtree', \n",
    "                    colsample_bytree = 0.8, \n",
    "                    gamma = 1, \n",
    "                    learning_rate = 0.1, \n",
    "                    max_depth = 7, \n",
    "                    min_child_weight = 10, \n",
    "                    n_estimators = 300,\n",
    "                    objective = 'binary:logistic', \n",
    "                    reg_alpha = 0.5, \n",
    "                    reg_lambda = 25)\n",
    "classifier3_tuned = SVC(C = 0.001, gamma = 0.1, kernel = 'poly', probability = True, random_state = 10)\n",
    "meta_classifier = LogisticRegression(random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_classifier_tuned = StackingCVClassifier(classifiers = [classifier1_tuned, classifier2_tuned, classifier3_tuned], \n",
    "                                          meta_classifier= meta_classifier, \n",
    "                                          random_state = 10)\n",
    "params = {'meta_classifier__C': [0.1, 10], \n",
    "         'meta_classifier__penalty': ['l1','l2'],\n",
    "         'meta_classifier__solver': ['lbfgs', 'liblinear']}\n",
    "\n",
    "grid = GridSearchCV(estimator = stacking_classifier_tuned, \n",
    "                   param_grid = params, \n",
    "                   cv=5, \n",
    "                   refit = True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\n\")\n",
    "print('Mean Cross Validation Score:' ,grid.best_score_)\n",
    "print('Parameters with Highest Cross Validation Score: ', grid.best_params_)\n",
    "print(\"Stacking Classifier Model's Best Accuracy: \", grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bd391",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1_tuned = KNeighborsClassifier(n_neighbors= 1, p= 1, leaf_size = 2)\n",
    "classifier2_tuned = XGBClassifier(booster = 'gbtree', \n",
    "                    colsample_bytree = 0.8, \n",
    "                    gamma = 1, \n",
    "                    learning_rate = 0.1, \n",
    "                    max_depth = 7, \n",
    "                    min_child_weight = 10, \n",
    "                    n_estimators = 300,\n",
    "                    objective = 'binary:logistic', \n",
    "                    reg_alpha = 0.5, \n",
    "                    reg_lambda = 25)\n",
    "classifier3_tuned = SVC(C = 0.001, gamma = 0.1, kernel = 'poly', probability = True, random_state = 10)\n",
    "meta_classifier = LogisticRegression(random_state = 10, C = 0.1, penalty = 'l2', solver = 'lbfgs')\n",
    "\n",
    "stacking_classifier_tuned = StackingCVClassifier(classifiers = [classifier1_tuned, classifier2_tuned, classifier3_tuned], \n",
    "                                          meta_classifier= meta_classifier, \n",
    "                                          random_state = 10)\n",
    "stacking_classifier.fit(X,y).score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710bd91",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The most important features: X1 and X5\n",
    "Accuracy of final model : 86.5%\n",
    "\n",
    "Whilst the stacked model reached an accuracy of 86.5%, and therefore, meets the success criteria, I would recommend that the area under the Receiver Operating Characteristic Curve is a better metric. This is because the AUC examines a models performance over varying threhold values. In this case, as we only have 126 datapoints, and with a 80:20 split of training and testing datasets, we have only 26 datapoints in the dataset. This means, an incorrect prediction in the very samll testing set will be penalised quite heavily. I noticed this as the accuracy scores, even with hypertuned parameters hovered around 69%. The advantage of using the AUC as the metric of choice is I would recommend we use the hypertuned support vector classifier model, as this has a highest AUC and is far simpler model than the stacked model. \n",
    "\n",
    "### Improvements to the Survey\n",
    "There were no missing data in the dataset which is quite spurious. It would be interesting to know how many people didn't reply to the survey- sometimes a lack of reply can be quite useful as well. \n",
    "\n",
    "With this in mind, we can see for X1: 'My order was delivered on time' there are no ratings of 1 for happy customers, and neither happy nor unsatisfied customers voted for a rating of 2. This could mean that the delivery time is relatively great, but it could mean there's not enough representation of each type of customers. For example, maybe there are unhappy customers who aren't actually filling out the survey and are also stopping use of services. In order to determine this, we need to look at how many customers are recurrent users, and what their responses were versus customers who stopped using the companies services. In addition, another important feature that was identified is X6: 'The app makes ordering easy for me'. It's noteworthy that a large proportion of unhappy customers gave this a rating of 3 whilst happy customers did mostly give this feature high ratings. So, additional information would be useful to address the problems unhappy customers are facing. One possible information could be devices/operating systems the users are openning the app on- this could help identify if there are specific OS users that are facing problems or not. \n",
    "\n",
    "Furthermore, there are quite a few cusotmers, both happy and unhappy customers, who were disappointed with the contents of their order. However, the vagueness of the question means we don't know what they were actually unhappy with. Were it the actual products or the products didn't match what they were advertised to be on the app? In order to gain a deeper understanding of this issue, the types of products information about the products would be useful. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272da94a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
